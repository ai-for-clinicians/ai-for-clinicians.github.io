<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns#">
	<head>
		<link href="http://gmpg.org/xfn/11" rel="profile">
		<meta http-equiv="X-UA-Compatible" content="IE=edge">
		<meta http-equiv="content-type" content="text/html; charset=utf-8">

		<!-- Metadata -->
			<meta name="description" content="" />
			<meta property="og:description" content="" />
			<meta property="og:title" content="AI for Clinical Search" />
			<meta property="og:type" content="website" />
			<meta property="og:url" content=".." />
		<meta property="og:image" content="../images/health-book-fill_inv.png" />

		<!-- Enable responsiveness on mobile devices-->
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

		<title>AI for Clinical Search - Engine comparison</title>

		<!-- CSS -->
		<link href="//fonts.googleapis.com/" rel="dns-prefetch">
		<link href="//fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic|Abril+Fatface|PT+Sans:400,400italic,700&amp;subset=latin,latin-ext" rel="stylesheet">

		<link rel="stylesheet" href="../theme/css/poole.css" />
		<link rel="stylesheet" href="../theme/css/hyde.css" />
		<link rel="stylesheet" href="../theme/css/syntax.css" />
			<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/fork-awesome@1.1.7/css/fork-awesome.min.css" crossorigin="anonymous">

		<!-- Feeds -->

		<!-- Analytics -->
	</head>

	<body class="theme-base-0d">
<div class="sidebar">
	<div class="container sidebar-sticky">
		<div class="sidebar-about">

			<h1>
				<a href="/">
					<img class="profile-picture" src="../images/health-book-fill_inv.png">
					AI for Clinical Search
				</a>
			</h1>
			<p class="lead"></p>
			<p class="lead"> </p>
			<p></p>
		</div>
			<ul class="sidebar-nav">
					<li><a href="../pages/clinical-questions.html">Clinical questions</a></li>
					<li><a href="../pages/improving-evidence-search.html">Improving evidence search</a></li>
					<li><a href="../pages/engine-comparison.html">Engine comparison</a></li>
					<li><a href="../pages/a-common-infrastructure.html">A common infrastructure</a></li>
					<li><a href="../pages/a-vision-for-the-future.html">A vision for the future</a></li>
					<li><a href="../pages/about-the-project.html">About the project</a></li>
			</ul>
		<nav class="sidebar-social">
		</nav>
			<p class="sidebar-footer">Â© 2021</p>
	</div>
</div>		<div class="content container">
    <h1>Engine comparison</h1>
    

    <p>Here, we provide a high-level comparison of a number of innovative clinical search engines. These are:</p>
<ul>
<li><strong>Trialstreamer</strong>: An innovative approach that combines a number of novel machine-learning based methods promising to deliver more precise results.</li>
<li><strong>Trip Database / Evidence Maps</strong>: A system that has been in the field for more than 20 years and combines a large collection independent of MEDLINE with innovative features, such as the evidence maps prototype.</li>
<li><strong>DOC Search</strong>: A commercial offering that relies on a number of machine-learning based methods similar to Trialstreamer.</li>
<li><strong>Cochrane PICOfinder</strong>: A system developed by one of the long-term leaders in the field that is based on a solid conceptualization of the domain using a knowledge graph.</li>
<li><strong>ScAIView</strong>: An academic, general-purpose search engine prototypical of a larger body of work that uses named entity recognition to guide retrieval.</li>
</ul>
<p>We first first present an overview in a product-feature matrix and then portray each tool in turn, focusing on the innovative aspects of each tool and the evaluation performed.</p>
<h1>Product-feature matrix</h1>
<div class="row-container">
<iframe src="https://docs.google.com/spreadsheets/d/e/2PACX-1vRvBgBdn_HsNVF8mFf6tfuE1ZUrozK7HcN76EqncgVBNxej_hsAX_CRnesF9XduXbL6ZimxGpDCbi0B/pubhtml?gid=661658554&amp;single=true&amp;widget=true&amp;headers=false" style="height: 60vh;width: 50vw;"></iframe>
</div>

<h1><a href="https://www.tripdatabase.com/">Trialstreamer</a></h1>
<p>A project by British and American academics. Built around natural-language processing (NLP) pipelines for article type classification (a binary classifier that selects randomized controlled trials), PICO extraction and automatic risk of bias estimation (using RobotReviewer, another text classification system developed by the same group). Additionally, NLP is also used for filtering out studies not conducted in humans and for extracting sample sizes. All NLP components have been evaluated on held-out data, using methodologically sound protocols. Especially PICO extraction and risk of bias estimation are challenging tasks still. For PICO extraction, recall for populations and interventions can be considered to be most important, as doctors would not want to miss a relevant study tailored to these aspects of their question. Here, the system achieves reasonably high scores (above 0.7), but at the cost of a relatively low precision, implying that many irrelevant articles will be retrieved. For risk of bias estimation, binary performance is even lower, so the authors resort to only enabling the use of the predicted risk for ranking documents, not for filtering. They demonstrate that the model is well-calibrated, meaning that the ordering imposed in this way is likely to be correct. Trialstreamer can be considered an impressive showcase for the underlying NLP technologies, deftly integrating them into a complete experience. Its features are directly tailored to clinicians during an evidence appraisal. Additionally, the platform has been regularly maintained for past year, with new trials being ingested via an automatic process. However, customization options are currently lacking, with a fairly limited search experience that for example lacks the option to also perform keyword search, rather than to just search for extracted PICO terms. The search system is built on a simple SQL database and lacks much of the capabilities for fine-grained search that comes with dedicated information retrieval backends. Another criticism concerns a lack of protections against data drift: The authors benchmarked the NLP components once, but outline no plans for monitoring their performance on the live data that is constantly ingested from various databases. In a widely discussed general trend, model performance tends to deteriorate as time progresses, so if run unchecked for years, the performance of the entire platform could worsen considerably over time, undermining the trust clinicians have placed in it. Finally, the coverage of the system is low, ingesting publications only from a small number of sources and processing only the abstract. </p>
<p><strong>Conclusion</strong>: Trialstreamer benchmarks NLP components and combines them into a minimally viable product for evidence search with a suitable core feature set.</p>
<h1><a href="https://www.tripdatabase.com/">Trip Database</a> / <a href="https://old.tripdatabase.com/evidencemaps">Evidence Maps</a></h1>
<p>Trip Database is a specialist search engine that has been in the market for over 20 years. Operated by a British for-profit company, the core product impresses mostly with its extensive coverage of literature from a wide variety of sources, including gray literature and guidelines from various health systems across the world. It is a polished product that aims mostly for a narrow audience, with many features locked behind a feature gate. However, the company also showcased an interesting prototype that leverages NLP technology, called Evidence Maps. 
This system indexes a subset of the publications in Trip Search (only primary literature and guidelines) and performs a number of NLP inference steps, specifically automatic extraction of population and intervention, sample size extraction and sentiment classification. In contrast to the result view of the standard trip search, which is centered around individual articles, evidence maps show interventions. The user searches for a given population (e.g. diabetics) and then receives a graphical summary of all interventions which contains the estimated effect (based on the sentiment of all articles mentioning it) and the strength of the evidence (the number of studies and reviews and their sample size and risk of bias factor in here). All NLP components are benchmarked on relatively small sets, showing sufficiently high performance. The system is highly innovative and interesting, but a full end-to-end evaluation of its fully automatic meta-analyses has not yet been performed, as it is only in a proof-of-concept stage. Especially the user of sentiment raises a number of questions, as its correlation with effect strengths and directions has not been analyzed rigorously. Moreover, the rather coarse-grained article-level analysis is likely to yield misleading results when more than two interventions are compared in one article. </p>
<p><strong>Conclusion</strong>: A highly innovative system that showcases the appeal of extracting and visualizing study results, but could benefit from future research and refinement.</p>
<h1><a href="https://covid-search.doctorevidence.com/">DOC Search</a></h1>
<p>A commercial product operated by an American company. While NLP is widely leveraged for many use cases such as tagging of medical concepts in abstract and article type classification, there is no publicly available benchmark data. In fact, there is so far no literature available that analyzes the performance of the system in any way. The system offers a feature-rich search experience, with Boolean search across keywords and medical terms arranged in hierarchies, filtering by data source, study type, geography and more. Results are richly annotated and link to trial data repositories where available. Various experimental features are exposed to the public as well, such as generation of extractive summaries from result lists or extraction of co-occurrence matrices and relationships between terms. The current design of the product implies a focus on power-users interested in fine-grained analysis of results retrieved, for example to identify gaps in the literature (e.g. by finding under-represented areas in the term co-occurrence matrices), with average clinicians likely being overwhelmed by the large array of seemingly irrelevant facets.</p>
<p><strong>Conclusion</strong>: A powerful commercial system that prominently leverages NLP, but has never been publicly evaluated.</p>
<h1><a href="https://www.cochranelibrary.com/en/advanced-search/pico">Cochrane PICOfinder</a></h1>
<p>The well-known British non-profit Cochrane offers a large repository of systematic reviews authored by its contributors. To make these more findable, Cochrane PICOfinder was released. The system currently indexes around 7000 reviews and a similarly large number of studies included in a least one review, implying that the vast number of primary studies referred to in reviews is not indexed so far. Individual records are tagged by PICO terms selected from a standardized ontology and users can search and filter exclusively by these terms. While unimpressive in coverage and feature set, the product is interesting due to its underlying architecture: Cochrane maintains an internal knowledge graph that stores the PICO information as well as additional trial information. This graph is based on four different ontologies: at the base, there a vocabulary which describes basic concepts such as drugs and conditions. It contains a taxonomy, i.e.\ hierarchical relations between diseases, and also links to other, widely used ontologies. One layer up, the PICO ontology describes a trial by its population, intervention, comparator and outcome, using concepts from the linked data vocabulary as slot fillers. Next, there is a content model. This is specific to the context in which the PICO annotation happens, e.g. what is being annotated. For Cochrane, what is being annotated are studies, reviews, sub-components of reviews, e.g. the meta-analysis and studies included. The content model describes a bibliographic record with metadata as the base class, and other content subclasses such as studies, which then have additional properties, such as study design or blinding. Content instances and PICO annotations are linked by means of a lightweight annotation model, which allows to add annotations with provenance information, i.e. indicating who annotated it when. Cochrane has also experimented with crowdsourcing workflows and has been a data provider for various NLP projects, but the PICO data used for PICOfinder is produced only by professional annotators as of yet.</p>
<p><strong>Conclusion</strong>: A showcase for a principled approach to storing annotation data leveraging a knowledge graph, but which currently has a very narrow scope unlikely to foster much uptake.</p>
<h1><a href="https://academia.scaiview.com/">ScAIView</a></h1>
<p>ScAIView is an academic project run by the German Fraunhofer society, prototypical for a larger set of academic approaches in this field. At the core of these projects, there is biomedical named entity recognition. Article abstracts are tagged using systems designed to find mentioned of specific terms from a large set of specialized ontologies, such as the gene ontology or MeSH terms. Many such search engines have been proposed, mostly targeting biomedical researchers, and ScAIView is no exception, offering a core search experience centered around retrieving article abstracts given a set of concept terms and analyzing term distributions in the list of results. While the core product fails to offer many innovative features, the supporting infrastructure is much more interesting. The system relies on an exemplary software architecture that neatly decouples functionalities into microservices: small, self-contained units of software. This approach allows for easily extensibility, as adding new NLP functionality is as easy as adding a new microservice that conforms to an existing scheme. Moreover, the architecture becomes scalable to large corpora, as new instances of services can easily be added to increase the workload the system can handle.</p>
<p><strong>Conclusion</strong>: A search engine that fails to impress due to its generic feature set and standard presentation of results, but offers interesting lessons in terms of software architecture.</p>

		</div>
	</body>
</html>